{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#tdqm = progress bar\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows\n",
    "nrows = 1000000\n",
    "# Chunksize = 10000 \n",
    "chunksize = 10000\n",
    "# Vitou's path\n",
    "path = 'C:/Users/Vitou/Downloads/train.csv'\n",
    "# Muna's path\n",
    "#path = '/Users/muna/Development/DataScience/new-york-city-taxi-fare-prediction/train.csv'\n",
    "# Columns to read from the data\n",
    "# Todo :split date into meaningful data\n",
    "# cols = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','fare_amount']\n",
    "cols = ['pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','fare_amount']\n",
    "\n",
    "#list to hold the batch dataframe\n",
    "df_list = []\n",
    "\n",
    "for df_chunk in tqdm(pd.read_csv(path,usecols=cols, chunksize=chunksize,nrows=nrows)):\n",
    "    df_list.append(df_chunk)\n",
    "    \n",
    "# Merge all dataframes into one dataframe\n",
    "data = pd.DataFrame()\n",
    "data = pd.concat(df_list)\n",
    "# # Delete the dataframe list to release memory\n",
    "del df_list, df_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Checking for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From our observation, there are some missing values, so we remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = data.dropna(how = 'any', axis = 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the description above, some of the fare_amount have negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remove all negatvie fare_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = data[(data['fare_amount'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a detailed look at the passenger count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['passenger_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest passenger count per taxi ride is 208, which is not possible. So we remove all passenger_count grater than 6, since 6 is the maximum passenger capacity for Uber/Lyft if the ride is an SUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[(data['passenger_count'] <= 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['passenger_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the highest passenger capacity is 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we remove all passenger count that are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['passenger_count'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['passenger_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7)) \n",
    "plt.hist(data['passenger_count'], bins=15) \n",
    "plt.xlabel('No. of Passengers') \n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above we see that single passengers are the most frequent travellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7)) \n",
    "plt.scatter(x=data['passenger_count'], y=data['fare_amount']) \n",
    "plt.xlabel('No. of Passengers') \n",
    "plt.ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the highest fare comes from the taxi that carry single passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the pickup|droppoff latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the info above, the maximum pickup_latitude/pickup_longtide/droppoff_latitude/dropoff_longitude are over 3000 WITH their respective minimum values are over -3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitudes range from -90 to 90 while longitudes range from -180 to 180, for single degree format. So we remove all values that are not with the latitude and longitude ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop((data[(data['pickup_latitude'] > 90) | (data['pickup_latitude'] < -90)]).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop((data[(data['pickup_longitude'] > 180) | (data['pickup_longitude'] < -180)]).index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for dropoff cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop((data[(data['dropoff_latitude'] > 90) | (data['dropoff_latitude'] < -90)]).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop((data[(data['dropoff_longitude'] > 180) | (data['dropoff_longitude'] < -180)]).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe, add two new features 'abs_diff_longitude' and\n",
    "# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In further observation, we have pickup_longitude, puckup_latitiude, dropoff_longitude and dropoff_latitude. We can calculate the distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates distance between pickup location and dropoff location\n",
    "def getDistance(lat1,lon1,lat2,lon2):\n",
    "    r = 6378 # earth's radius\n",
    "    lat1 = np.deg2rad(lat1)\n",
    "    lon1 = np.deg2rad(lon1)\n",
    "    lat2 = np.deg2rad(lat2)\n",
    "    lon2 = np.deg2rad(lon2)\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    distance = r*c\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Add new cloumn \"distance\" to the data\n",
    "data['distance'] = getDistance(data.pickup_latitude, data.pickup_longitude, \n",
    "                                      data.dropoff_latitude, data.dropoff_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['distance'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some distances which are zero. so we remove all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['distance'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(data[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new features like year, month, day, hour and dayOfWeek from pickup_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetime(df):\n",
    "        df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format=\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "        df['year'] = df['pickup_datetime'].dt.year\n",
    "        df['month'] = df['pickup_datetime'].dt.month\n",
    "        df['day'] = df['pickup_datetime'].dt.day\n",
    "        df['hour'] = df['pickup_datetime'].dt.hour\n",
    "        df['dayOfWeek'] = df['pickup_datetime'].dt.dayofweek\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "split_datetime(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7)) \n",
    "plt.scatter(x=data['dayOfWeek'], y=data['fare_amount'], s=1.5) \n",
    "plt.xlabel('Day of Week') \n",
    "plt.ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest fare_amount seen to be on a Friday while the lowest is on s Saturday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split pickup_datetime into year, month, day, hour and year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at hour and dayOfWeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data['hour'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to New York Times, rush hours is ususally between 7 to 9AM and from 4 to 6PM. Let's create a new feature from hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for rush hour, 0 for not\n",
    "def rush_hour(hour):\n",
    "    if hour in range(7, 10) or hour in range(16, 19):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data['rush_hour'] = data['hour'].apply(rush_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['dayOfWeek'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new feature from daysOfWeek. We can check if it's a weekend or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for weekend, 0 for not\n",
    "def weekend(dayOfWeek):\n",
    "    if dayOfWeek == 0 or dayOfWeek == 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['weekend'] = data['dayOfWeek'].apply(weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rush_hour and weekend are categorical either 1 or 0, so we can crerate dummy columns from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['rush_hour','weekend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=data['year'],y=data[\"fare_amount\"],data=data).set_title(\"Fare Amount over Years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, it Looks like fares have been incrasing over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_cols = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count',\n",
    "                'abs_diff_longitude','abs_diff_latitude','distance','year','month','day','hour','dayOfWeek',\n",
    "                'rush_hour_0','rush_hour_1','weekend_0','weekend_1']\n",
    "\n",
    "X = data[feature_cols] \n",
    "y = data['fare_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Alogorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training of the datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_linreg = LinearRegression(n_jobs=-1)\n",
    "my_linreg.fit(X_train, y_train)\n",
    "y_prediction_lr = my_linreg.predict(X_test)\n",
    "mse = metrics.mean_squared_error(y_test, y_prediction_lr)\n",
    "rmse_lr = np.sqrt(mse)\n",
    "print(f'Linear Regression:{rmse_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding the  y_test and y to prevent continous error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "y_encoded = lab_enc.fit_transform(y)\n",
    "y_test_encoded = lab_enc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#max_iter default = 100\n",
    "my_logreg = LogisticRegression(max_iter=20,solver='sag',multi_class='auto',n_jobs=-1)\n",
    "my_logreg.fit(X_train, y_train_encoded)\n",
    "y_prediction_log = my_logreg.predict(X_test)\n",
    "mse_log = metrics.mean_squared_error(y_test, y_prediction_log)\n",
    "rmse_log = np.sqrt(mse_log)\n",
    "print(f'Logistic Regression: {rmse_log}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "my_rfr = RandomForestRegressor(n_estimators = 10, bootstrap=True, random_state=3)\n",
    "my_rfr.fit(X_train, y_train)\n",
    "y_prediction_rfr = my_rfr.predict(X_test)\n",
    "mse_rfr = metrics.mean_squared_error(y_test, y_prediction_rfr)\n",
    "rmse_rfr = np.sqrt(mse_rfr)\n",
    "print(f'Random Forest Regressor: {rmse_rfr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSME Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "y_axis = ('Linear Regression','Logistic Regression','Random Forest Regressor')\n",
    "y_pos = np.arange(len(y_axis))\n",
    "width = 0.75 \n",
    "x_axis = (round(rmse_lr,4),round(rmse_log,4),round(rmse_rfr,4))\n",
    "ax.barh(y_pos, x_axis, width,align='center')\n",
    "for i, v in enumerate(x_axis):\n",
    "    ax.text(v, i, '$'+str(v), color='blue', fontweight='bold')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(y_axis)\n",
    "ax.set_xlabel('RMSE')\n",
    "ax.set_title('RMSE Values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
